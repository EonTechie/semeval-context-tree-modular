{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train & Evaluate: Separate Models\n",
        "\n",
        "This notebook trains classifiers on features from each model separately.\n",
        "\n",
        "**Steps:**\n",
        "1. Load features from Drive (saved by 02_feature_extraction_separate.ipynb)\n",
        "2. Train multiple classifiers (LogisticRegression, LinearSVC, RandomForest, XGBoost, LightGBM)\n",
        "3. Evaluate on Dev set\n",
        "4. Save predictions and probabilities to Drive\n",
        "5. Print results tables and create plots\n",
        "\n",
        "**Output:** Predictions, probabilities, and results saved to Drive for each model/classifier/task combination.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup (run previous notebooks first)\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "BASE_PATH = Path('/content/semeval-context-tree-modular')\n",
        "DATA_PATH = Path('/content/drive/MyDrive/semeval_data')\n",
        "sys.path.insert(0, str(BASE_PATH))\n",
        "\n",
        "from src.storage.manager import StorageManager\n",
        "from src.models.trainer import train_and_evaluate\n",
        "from src.models.classifiers import get_classifier_dict\n",
        "\n",
        "storage = StorageManager(\n",
        "    base_path=str(BASE_PATH),\n",
        "    data_path=str(DATA_PATH),\n",
        "    github_path=str(BASE_PATH)\n",
        ")\n",
        "\n",
        "# Load splits for labels\n",
        "train_ds = storage.load_split('train')\n",
        "dev_ds = storage.load_split('dev')\n",
        "\n",
        "print(\"✅ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model and task configurations\n",
        "MODELS = ['bert', 'roberta', 'deberta', 'xlnet']\n",
        "TASKS = ['clarity', 'evasion']\n",
        "\n",
        "# Label mappings\n",
        "CLARITY_LABELS = ['Clear Reply', 'Ambiguous', 'Clear Non-Reply']\n",
        "EVASION_LABELS = ['Direct Answer', 'Partial Answer', 'Implicit Answer', \n",
        "                  'Uncertainty', 'Refusal', 'Clarification', \n",
        "                  'Question', 'Topic Shift', 'Other']\n",
        "\n",
        "# Get classifiers\n",
        "classifiers = get_classifier_dict(random_state=42)\n",
        "print(f\"✅ Classifiers: {list(classifiers.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and evaluate for each model and task\n",
        "all_results = {}\n",
        "\n",
        "for model in MODELS:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"MODEL: {model.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    all_results[model] = {}\n",
        "    \n",
        "    for task in TASKS:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"TASK: {task.upper()}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        # Get label list\n",
        "        if task == 'clarity':\n",
        "            label_list = CLARITY_LABELS\n",
        "            label_key = 'clarity_label'\n",
        "        else:  # evasion\n",
        "            label_list = EVASION_LABELS\n",
        "            label_key = 'evasion_label'\n",
        "        \n",
        "        # Load features\n",
        "        print(\"Loading features...\")\n",
        "        X_train = storage.load_features(model, task, 'train')\n",
        "        X_dev = storage.load_features(model, task, 'dev')\n",
        "        \n",
        "        # Get labels\n",
        "        y_train = np.array([train_ds[i][label_key] for i in range(len(train_ds))])\n",
        "        y_dev = np.array([dev_ds[i][label_key] for i in range(len(dev_ds))])\n",
        "        \n",
        "        print(f\"  Train: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
        "        print(f\"  Dev: {X_dev.shape[0]} samples, {X_dev.shape[1]} features\")\n",
        "        \n",
        "        # Train and evaluate\n",
        "        results = train_and_evaluate(\n",
        "            X_train, y_train, X_dev, y_dev,\n",
        "            label_list=label_list,\n",
        "            task_name=f\"{model}_{task}\",\n",
        "            classifiers=classifiers,\n",
        "            random_state=42,\n",
        "            print_report=True,\n",
        "            print_table=True,\n",
        "            create_plots=True,\n",
        "            save_plots_dir=str(DATA_PATH / 'plots')\n",
        "        )\n",
        "        \n",
        "        # Save predictions and probabilities\n",
        "        for classifier_name, result in results.items():\n",
        "            # Save predictions (hard labels)\n",
        "            storage.save_predictions(\n",
        "                result['dev_pred'],\n",
        "                model, classifier_name, task, 'dev'\n",
        "            )\n",
        "            \n",
        "            # Save probabilities (if available)\n",
        "            if result['dev_proba'] is not None:\n",
        "                storage.save_probabilities(\n",
        "                    result['dev_proba'],\n",
        "                    model, classifier_name, task, 'dev'\n",
        "                )\n",
        "        \n",
        "        all_results[model][task] = results\n",
        "        \n",
        "        # Save results summary\n",
        "        experiment_id = f\"{model}_{task}_separate\"\n",
        "        storage.save_results({\n",
        "            'model': model,\n",
        "            'task': task,\n",
        "            'results': {\n",
        "                name: {\n",
        "                    'metrics': res['metrics'],\n",
        "                    'n_train': len(y_train),\n",
        "                    'n_dev': len(y_dev)\n",
        "                }\n",
        "                for name, res in results.items()\n",
        "            }\n",
        "        }, experiment_id)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"✅ Training and evaluation complete for all models!\")\n",
        "print(f\"{'='*80}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
