{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Split: Train / Dev / Test\n",
        "\n",
        "================================================================================\n",
        "PURPOSE: Split dataset into Train/Dev/Test sets to prevent data leakage\n",
        "================================================================================\n",
        "\n",
        "This notebook performs the initial data split that is critical for preventing\n",
        "data leakage in the experimental pipeline. The dataset is divided into three\n",
        "non-overlapping sets:\n",
        "\n",
        "- **Train**: Used for training models (70% of data)\n",
        "- **Dev**: Used for model selection, feature selection, and hyperparameter\n",
        "  tuning (15% of data)\n",
        "- **Test**: **ONLY** used in final evaluation notebook (15% of data). This set\n",
        "  is never used for training, model selection, or any development decisions.\n",
        "\n",
        "**CRITICAL**: The test set is separated FIRST and will ONLY be accessed in the\n",
        "final evaluation notebook (05_final_evaluation.ipynb). This ensures fair and\n",
        "unbiased evaluation according to competition rules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SETUP: Repository Clone, Drive Mount, and Path Configuration\n",
        "# ============================================================================\n",
        "# This cell performs minimal setup required for the notebook to run:\n",
        "# 1. Clones repository from GitHub (if not already present)\n",
        "# 2. Mounts Google Drive for persistent data storage\n",
        "# 3. Configures Python paths and initializes StorageManager\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Repository configuration\n",
        "repo_dir = '/content/semeval-context-tree-modular'\n",
        "repo_url = 'https://github.com/EonTechie/semeval-context-tree-modular.git'\n",
        "zip_url = 'https://github.com/EonTechie/semeval-context-tree-modular/archive/refs/heads/main.zip'\n",
        "\n",
        "# Clone repository (if not already present)\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"Cloning repository from GitHub...\")\n",
        "    max_retries = 2\n",
        "    clone_success = False\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                ['git', 'clone', repo_url],\n",
        "                cwd='/content',\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=60\n",
        "            )\n",
        "            if result.returncode == 0:\n",
        "                print(\"Repository cloned successfully via git\")\n",
        "                clone_success = True\n",
        "                break\n",
        "            else:\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(3)\n",
        "        except Exception as e:\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(3)\n",
        "    \n",
        "    # Fallback: Download as ZIP if git clone fails\n",
        "    if not clone_success:\n",
        "        print(\"Git clone failed. Downloading repository as ZIP archive...\")\n",
        "        zip_path = '/tmp/repo.zip'\n",
        "        try:\n",
        "            response = requests.get(zip_url, stream=True, timeout=60)\n",
        "            response.raise_for_status()\n",
        "            with open(zip_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content')\n",
        "            extracted_dir = '/content/semeval-context-tree-modular-main'\n",
        "            if os.path.exists(extracted_dir):\n",
        "                os.rename(extracted_dir, repo_dir)\n",
        "            os.remove(zip_path)\n",
        "            print(\"Repository downloaded and extracted successfully\")\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Failed to obtain repository: {e}\")\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "except Exception:\n",
        "    pass  # Already mounted\n",
        "\n",
        "# Configure paths\n",
        "BASE_PATH = Path('/content/semeval-context-tree-modular')\n",
        "DATA_PATH = Path('/content/drive/MyDrive/semeval_data')\n",
        "sys.path.insert(0, str(BASE_PATH))\n",
        "\n",
        "# Initialize StorageManager\n",
        "from src.storage.manager import StorageManager\n",
        "storage = StorageManager(\n",
        "    base_path=str(BASE_PATH),\n",
        "    data_path=str(DATA_PATH),\n",
        "    github_path=str(BASE_PATH)\n",
        ")\n",
        "\n",
        "print(\"Setup complete\")\n",
        "print(f\"  Repository: {BASE_PATH}\")\n",
        "print(f\"  Data storage: {DATA_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LOAD DATASET FROM HUGGINGFACE HUB\n",
        "# ============================================================================\n",
        "# Loads the QEvasion dataset from HuggingFace Hub\n",
        "# The dataset contains question-answer pairs with clarity and evasion labels\n",
        "\n",
        "from src.data.loader import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_name=\"ailsntua/QEvasion\")\n",
        "train_raw = dataset['train']\n",
        "\n",
        "print(f\"Dataset loaded: {len(train_raw)} samples\")\n",
        "print(f\"Dataset features: {list(train_raw.features.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SPLIT DATASET INTO TRAIN / DEV / TEST\n",
        "# ============================================================================\n",
        "# Performs stratified split to maintain label distribution across splits\n",
        "# Test set is separated FIRST and will ONLY be used in final evaluation\n",
        "# This ensures no data leakage during model development\n",
        "\n",
        "from src.data.splitter import split_dataset\n",
        "\n",
        "train_ds, dev_ds, test_ds = split_dataset(\n",
        "    dataset=train_raw,\n",
        "    test_ratio=0.15,  # 15% reserved for final test evaluation\n",
        "    dev_ratio=0.15,   # 15% for development (model/feature selection)\n",
        "    seed=42            # Fixed seed for reproducibility\n",
        ")\n",
        "\n",
        "print(\"Dataset split completed:\")\n",
        "print(f\"  Train: {len(train_ds)} samples ({len(train_ds)/len(train_raw)*100:.1f}%)\")\n",
        "print(f\"  Dev: {len(dev_ds)} samples ({len(dev_ds)/len(train_raw)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(test_ds)} samples ({len(test_ds)/len(train_raw)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVE SPLITS TO PERSISTENT STORAGE\n",
        "# ============================================================================\n",
        "# Saves the three splits to Google Drive for use in subsequent notebooks\n",
        "# Splits are saved in a format that preserves all dataset features and metadata\n",
        "\n",
        "storage.save_splits(train_ds, dev_ds, test_ds)\n",
        "\n",
        "print(\"Splits saved to persistent storage\")\n",
        "print(f\"  Train: {len(train_ds)} samples\")\n",
        "print(f\"  Dev: {len(dev_ds)} samples\")\n",
        "print(f\"  Test: {len(test_ds)} samples\")\n",
        "print(\"\\nIMPORTANT: Test set will ONLY be used in final evaluation notebook\")\n",
        "print(\"           (05_final_evaluation.ipynb). Do not use it for development!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
